Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	add_query_msa
	1	all
	1	blast
	1	ete3
	1	fasttree
	1	gb_parsing
	1	gb_pull
	1	mafft
	1	trimal
	9

[Wed Dec  4 10:39:44 2019]
rule blast:
    input: data/queries/Pongo_abelii.fasta
    output: data/blast_out_accs/Pongo_abelii
    jobid: 8
    wildcards: sample=Pongo_abelii

[Wed Dec  4 10:39:44 2019]
Error in rule blast:
    jobid: 8
    output: data/blast_out_accs/Pongo_abelii
    shell:
        blastn -db nt -query data/queries/Pongo_abelii.fasta -out data/blast_out_accs/Pongo_abelii -evalue 0.001 -max_target_seqs 5 -outfmt '10 sacc' -remote
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job blast since they might be corrupted:
data/blast_out_accs/Pongo_abelii
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/531734/mike/blast-snake/.snakemake/log/2019-12-04T103944.183270.snakemake.log
